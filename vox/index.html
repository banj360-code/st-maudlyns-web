<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Electronic Confessional</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <div class="container">
        <h1>The Electronic Confessional</h1>
        <p class="subtitle">Reverend Bassette will see you now.</p>

        <div id="bishop-container" style="display:none;">
            <img id="bishop-body" src="../images/bishop-body.png" alt="Reverend Body">
            <img id="bishop-jaw" src="../images/bishop-jaw.png" alt="Reverend Jaw">
        </div>

        <form id="confession-form">
            <textarea id="confession" placeholder="Confess your sins, my child... (e.g., 'I skipped church for football' or 'I voted Tory')" required></textarea>
            <br>
            <button type="submit" id="submit-btn">Seek Absolution</button>
        </form>

        <div id="result" class="result-box"></div>
    </div>

    <script>
    // Helper to decode the Base64 audio string
    function base64ToArrayBuffer(base64) {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    }

    let audioContext; // Store context globally to reuse

    document.getElementById("confession-form").addEventListener("submit", async (e) => {
        e.preventDefault();
        
        const confession = document.getElementById("confession").value;
        const resultDiv = document.getElementById("result");
        const submitBtn = document.getElementById("submit-btn");
        const bishopContainer = document.getElementById("bishop-container");
        const bishopJaw = document.getElementById("bishop-jaw");

        // Initialize AudioContext immediately on user interaction
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        if (audioContext.state === 'suspended') {
            await audioContext.resume();
        }

        // UI State: Loading
        resultDiv.innerText = "The Reverend is contemplating your sins...";
        resultDiv.style.opacity = "1";
        submitBtn.disabled = true;
        submitBtn.innerText = "Praying...";

        try {
            // Call the Netlify Function
            const response = await fetch('/.netlify/functions/the-reverend', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ confession })
            });

            const data = await response.json();

            if (response.status === 200) {
                resultDiv.innerText = data.absolution;

                // --- AUDIO & ANIMATION LOGIC ---
                
                // 1. Decode the audio data
                const audioBuffer = await audioContext.decodeAudioData(base64ToArrayBuffer(data.audio));
                
                // 2. Create Audio Source & Analyser
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 32; // Low setting for performance, good for volume
                
                source.connect(analyser);
                analyser.connect(audioContext.destination);

                // 3. Show the Bishop
                bishopContainer.style.display = "block";

                // 4. Animation Loop
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                let animationId;

                function animateJaw() {
                    analyser.getByteFrequencyData(dataArray);

                    // Calculate average volume
                    let sum = 0;
                    for(let i = 0; i < dataArray.length; i++) {
                        sum += dataArray[i];
                    }
                    const volume = sum / dataArray.length;

                    // Threshold: Only move if there is actual sound (removes "jitters")
                    if (volume > 10) {
                        // Map volume to movement
                        // We cap it at 12px (20% less than previous 15px)
                        // '0.1' is the sensitivity multiplier
                        const movement = Math.min(volume * 0.1, 12); 
                        bishopJaw.style.transform = `translateY(${movement}px)`;
                    } else {
                        // Close jaw during silence
                        bishopJaw.style.transform = `translateY(0px)`;
                    }

                    animationId = requestAnimationFrame(animateJaw);
                }

                // Start playback and animation
                source.start(0);
                animateJaw();

                // Cleanup when audio finishes
                source.onended = () => {
                    cancelAnimationFrame(animationId);
                    bishopJaw.style.transform = `translateY(0px)`; // Ensure jaw closes
                    submitBtn.disabled = false;
                    submitBtn.innerText = "Seek Absolution";
                };

            } else {
                throw new Error(data.absolution || "The Reverend remains silent.");
            }

        } catch (error) {
            console.error("Error:", error);
            resultDiv.innerText = "The Reverend is indisposed. (Error: " + error.message + ")";
            submitBtn.disabled = false;
            submitBtn.innerText = "Try Again";
        }
    });
</script>
</body>
</html>